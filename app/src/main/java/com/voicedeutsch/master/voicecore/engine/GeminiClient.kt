package com.voicedeutsch.master.voicecore.engine

import android.util.Log
import androidx.annotation.RequiresPermission
import com.google.firebase.Firebase
import com.google.firebase.ai.ai
import com.google.firebase.ai.type.FunctionCallPart
import com.google.firebase.ai.type.FunctionDeclaration
import com.google.firebase.ai.type.FunctionResponsePart
import com.google.firebase.ai.type.InlineDataPart
import com.google.firebase.ai.type.LiveServerContent
import com.google.firebase.ai.type.LiveServerMessage
import com.google.firebase.ai.type.LiveSession
import com.google.firebase.ai.type.PublicPreviewAPI
import com.google.firebase.ai.type.ResponseModality
import com.google.firebase.ai.type.Schema
import com.google.firebase.ai.type.SpeechConfig
import com.google.firebase.ai.type.TextPart
import com.google.firebase.ai.type.Tool
import com.google.firebase.ai.type.Transcription
import com.google.firebase.ai.type.Voice
import com.google.firebase.ai.type.content
import com.google.firebase.ai.type.liveGenerationConfig
import com.voicedeutsch.master.voicecore.context.ContextBuilder
import kotlinx.coroutines.CoroutineScope
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.Job
import kotlinx.coroutines.SupervisorJob
import kotlinx.coroutines.cancel
import kotlinx.coroutines.channels.Channel
import kotlinx.coroutines.flow.Flow
import kotlinx.coroutines.flow.flow
import kotlinx.coroutines.launch
import kotlinx.serialization.json.Json
import kotlinx.serialization.json.JsonObject
import kotlinx.serialization.json.JsonPrimitive
import kotlinx.serialization.json.buildJsonObject

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Ğ˜Ğ¢ĞĞ“ ĞĞ¢Ğ›ĞĞ”ĞšĞ˜ (Ñ„ĞµĞ²Ñ€Ğ°Ğ»ÑŒ 2026, BoM 34.9.0, firebase-ai SDK):
//
// âœ… Ğ¡Ğ£Ğ©Ğ•Ğ¡Ğ¢Ğ’Ğ£Ğ®Ğ¢ (Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¾ ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»ÑÑ‚Ğ¾Ñ€Ğ¾Ğ¼ â€” Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ñ‹ ĞĞ• Ğ´Ğ°Ğ²Ğ°Ğ»Ğ¸ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº):
//    - LiveSession          (com.google.firebase.ai.type)
//    - LiveServerMessage    (com.google.firebase.ai.type) â€” sealed class
//    - LiveServerContent    (com.google.firebase.ai.type) â€” Ğ¿Ğ¾Ğ´Ñ‚Ğ¸Ğ¿ LiveServerMessage
//    - FunctionCallPart, FunctionResponsePart, FunctionDeclaration
//    - InlineDataPart, TextPart, Tool, Schema, Voice, SpeechConfig
//
// âŒ ĞĞ• Ğ¡Ğ£Ğ©Ğ•Ğ¡Ğ¢Ğ’Ğ£Ğ®Ğ¢ (Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¾ ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»ÑÑ‚Ğ¾Ñ€Ğ¾Ğ¼):
//    - LiveContentResponse  â†’ Ğ¤ĞĞĞ¢ĞĞœ, Ğ½ĞµÑ‚ Ğ² SDK
//    - GenerativeBackend    â†’ ĞºĞ°Ğº Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ½Ğµ Ñ€ĞµĞ·Ğ¾Ğ»Ğ²Ğ¸Ñ‚ÑÑ
//    - LiveGenerativeModel  â†’ Ñ‚Ğ¸Ğ¿ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑÑ, ÑĞ²Ğ½Ñ‹Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶ĞµĞ½
//    - AudioTranscriptionConfig â†’ Ğ½ĞµÑ‚ Ğ² Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸
//
// ğŸ“ ĞšĞ›Ğ®Ğ§Ğ•Ğ’Ğ«Ğ• Ğ¡Ğ˜Ğ“ĞĞĞ¢Ğ£Ğ Ğ« (Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ñ‹ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ğ¼Ğ¸ ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»ÑÑ‚Ğ¾Ñ€Ğ°):
//    - session.send(content: Content)  â€” ĞĞ”Ğ˜Ğ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€, Ğ±ĞµĞ· turnComplete
//    - session.send(text: String)      â€” ĞĞ”Ğ˜Ğ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€, Ğ±ĞµĞ· turnComplete
//    - session.receive() â†’ Flow<LiveServerMessage>
//    - LiveServerContent ÑĞ²Ğ¾Ğ¹ÑÑ‚Ğ²Ğ° (Ğ¸Ğ· PR #7482):
//        content: Content, turnComplete: Boolean, interrupted: Boolean,
//        generationComplete: Boolean, inputTranscription: Transcription,
//        outputTranscription: Transcription
//
// âš ï¸ Ğ’ĞĞ—ĞœĞĞ–ĞĞ«Ğ• ĞŸĞ ĞĞ’ĞšĞ˜ ĞŸĞĞ¡Ğ›Ğ• Ğ‘Ğ˜Ğ›Ğ”Ğ:
//    1. Ğ•ÑĞ»Ğ¸ receive() Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Flow<LiveServerContent> Ğ²Ğ¼ĞµÑÑ‚Ğ¾
//       Flow<LiveServerMessage> â€” ÑƒĞ±Ñ€Ğ°Ñ‚ÑŒ when Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ.
//    2. Ğ•ÑĞ»Ğ¸ LiveServerContent.content nullable â€” ÑƒĞ¶Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾ Ñ‡ĞµÑ€ĞµĞ· ?.parts.
//    3. Ğ•ÑĞ»Ğ¸ InlineDataPart.inlineData Ğ½Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚ â€” Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ .data Ğ¸Ğ»Ğ¸ .bytes.
//    4. Ğ•ÑĞ»Ğ¸ Transcription.text Ğ½Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚ â€” Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ .content Ğ¸Ğ»Ğ¸ toString().
//    5. Ğ•ÑĞ»Ğ¸ FunctionCallPart.args â€” Ğ½Ğµ Map, Ğ° JsonObject â€” Ğ¿Ğ¾Ğ¼ĞµĞ½ÑÑ‚ÑŒ .toString().
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * GeminiClient â€” Ğ¾Ğ±Ñ‘Ñ€Ñ‚ĞºĞ° Ğ½Ğ°Ğ´ Firebase AI Logic Live API SDK.
 *
 * ĞĞ£Ğ”Ğ˜Ğ Ğ¤ĞĞ ĞœĞĞ¢:
 *   Ğ’Ñ…Ğ¾Ğ´:  PCM 16-bit, 16 kHz, mono  â†’ session.send(content { inlineData(...) })
 *   Ğ’Ñ‹Ñ…Ğ¾Ğ´: PCM 16-bit, 24 kHz, mono  â† LiveServerContent.content.parts[InlineDataPart]
 *
 * @param config  ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (model name, voice, sample rates Ğ¸ Ñ‚.Ğ´.)
 * @param json    ÑĞºĞ·ĞµĞ¼Ğ¿Ğ»ÑÑ€ Json Ğ´Ğ»Ñ ÑĞµÑ€Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ function declarations
 */
@OptIn(PublicPreviewAPI::class)
class GeminiClient(
    private val config: GeminiConfig,
    private val json: Json,
) {
    companion object {
        private const val TAG = "GeminiClient"
        private const val DEFAULT_MODEL = "gemini-2.5-flash-native-audio-preview-12-2025"
        private const val AUDIO_INPUT_MIME = "audio/pcm;rate=16000"
    }

    // â”€â”€ Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    private val clientScope = CoroutineScope(SupervisorJob() + Dispatchers.IO)

    @Volatile private var liveSession: LiveSession? = null
    private var audioConversationJob: Job? = null

    private val responseChannel = Channel<GeminiResponse>(Channel.UNLIMITED)

    // â”€â”€ Public API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /**
     * ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ÑÑ Ğº Gemini Live API.
     *
     * Firebase.ai.liveModel() â€” backend Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ googleAI.
     * liveModel.connect() â†’ LiveSession.
     */
    suspend fun connect(context: ContextBuilder.SessionContext) {
        try {
            Log.d(TAG, "Connecting to Gemini Live API [model=${config.modelName}]")

            val functionDeclarations: List<FunctionDeclaration> = context.functionDeclarations
                .mapNotNull { declarationJson ->
                    runCatching { parseFunctionDeclaration(declarationJson) }
                        .onFailure { Log.w(TAG, "Skipping invalid function declaration: ${it.message}") }
                        .getOrNull()
                }

            val tools: List<Tool>? = functionDeclarations
                .takeIf { it.isNotEmpty() }
                ?.let { listOf(Tool.functionDeclarations(it)) }

            val systemInstruction = content(role = "user") {
                text(context.fullContext)
            }

            val liveModel = Firebase.ai.liveModel(
                modelName = config.modelName.ifBlank { DEFAULT_MODEL },
                generationConfig = liveGenerationConfig {
                    responseModality = ResponseModality.AUDIO
                    speechConfig = SpeechConfig(
                        voice = Voice(config.voiceName)
                    )
                },
                tools = tools,
                systemInstruction = systemInstruction,
            )

            liveSession = liveModel.connect()
            Log.d(TAG, "âœ… LiveSession established")
        } catch (e: Exception) {
            Log.e(TAG, "âŒ connect() failed: ${e.message}", e)
            throw GeminiConnectionException("Failed to connect to Gemini Live API", e)
        }
    }

    suspend fun disconnect() {
        try {
            audioConversationJob?.cancel()
            audioConversationJob = null
            liveSession?.close()
            liveSession = null
            responseChannel.close()
            Log.d(TAG, "LiveSession closed")
        } catch (e: Exception) {
            Log.w(TAG, "disconnect() warning: ${e.message}")
        }
    }

    /**
     * ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ chunk PCM-Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ² Gemini Live API.
     * Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚: PCM 16-bit signed, 16 kHz, mono.
     *
     * âœ… session.send(content: Content) â€” ĞĞ”Ğ˜Ğ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€, Ğ±ĞµĞ· turnComplete.
     */
    suspend fun sendAudioChunk(pcmBytes: ByteArray) {
        val session = liveSession ?: run {
            Log.w(TAG, "sendAudioChunk: no active session, dropping chunk")
            return
        }
        runCatching {
            val audioContent = content {
                inlineData(pcmBytes, AUDIO_INPUT_MIME)
            }
            session.send(audioContent)
        }.onFailure { e ->
            Log.e(TAG, "sendAudioChunk error: ${e.message}", e)
        }
    }

    /**
     * ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ² Gemini Live API.
     *
     * âœ… session.send(text: String) â€” ĞĞ”Ğ˜Ğ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€, Ğ±ĞµĞ· turnComplete.
     */
    suspend fun sendText(text: String) {
        val session = liveSession ?: run {
            Log.w(TAG, "sendText: no active session")
            return
        }
        runCatching {
            session.send(text)
        }.onFailure { e ->
            Log.e(TAG, "sendText error: ${e.message}", e)
        }
    }

    /**
     * ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾ Ğ² Gemini.
     *
     * âœ… FunctionResponsePart(name, response) â€” Ğ±ĞµĞ· id.
     */
    suspend fun sendFunctionResult(callId: String, name: String, resultJson: String) {
        val session = liveSession ?: run {
            Log.w(TAG, "sendFunctionResult: no active session")
            return
        }
        runCatching {
            val responseJson = try {
                json.parseToJsonElement(resultJson) as? JsonObject
                    ?: buildJsonObject { put("result", JsonPrimitive(resultJson)) }
            } catch (e: Exception) {
                buildJsonObject { put("result", JsonPrimitive(resultJson)) }
            }

            val functionResponse = FunctionResponsePart(
                name     = name,
                response = responseJson,
            )
            session.sendFunctionResponse(listOf(functionResponse))
        }.onFailure { e ->
            Log.e(TAG, "sendFunctionResult error: ${e.message}", e)
        }
    }

    /**
     * Cold Flow Ğ²Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ñ… Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ¾Ñ‚ Gemini.
     *
     * âœ… session.receive() â†’ Flow<LiveServerMessage>
     *
     * LiveServerMessage â€” sealed class. ĞŸĞ¾Ğ´Ñ‚Ğ¸Ğ¿Ñ‹:
     *   - LiveServerContent â†’ Ğ°ÑƒĞ´Ğ¸Ğ¾/Ñ‚ĞµĞºÑÑ‚/function calls/Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸
     *   - (Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ â€” Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼)
     *
     * LiveServerContent.content.parts ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚:
     *   - InlineDataPart â†’ Ğ°ÑƒĞ´Ğ¸Ğ¾ (PCM 24kHz)
     *   - TextPart â†’ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚
     *   - FunctionCallPart â†’ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ñ‹ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¹ (Ğ¿Ñ€Ğ¸ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ¼ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ)
     *
     * âš ï¸ Ğ•ÑĞ»Ğ¸ receive() Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Flow<LiveServerContent> Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ â€”
     *    ÑƒĞ±ĞµÑ€Ğ¸Ñ‚Ğµ when(message) Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ¹Ñ‚Ğµ Ñ LiveServerContent ÑÑ€Ğ°Ğ·Ñƒ.
     */
    fun receiveFlow(): Flow<GeminiResponse> = flow {
        val session = liveSession
            ?: throw GeminiConnectionException("receiveFlow: no active session")

        try {
            session.receive().collect { message ->
                mapServerMessage(message)?.let { emit(it) }
            }
        } catch (e: Exception) {
            Log.e(TAG, "receiveFlow error: ${e.message}", e)
            throw e
        }
    }

    /**
     * Ğ ĞµĞ¶Ğ¸Ğ¼ A: SDK ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ·Ğ°Ñ…Ğ²Ğ°Ñ‚Ğ¾Ğ¼ Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ğ° Ğ¸ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸ĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾.
     *
     * âœ… startAudioConversation â€” Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµĞ¼Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Firebase.
     * Handles: audio capture â†’ send â†’ receive â†’ playback + function calling + transcription.
     */
    @RequiresPermission(android.Manifest.permission.RECORD_AUDIO)
    fun startManagedAudioConversation(
        functionCallHandler: ((FunctionCallPart) -> FunctionResponsePart)? = null,
        transcriptHandler: ((Transcription?, Transcription?) -> Unit)? = null,
    ) {
        val session = liveSession ?: run {
            Log.e(TAG, "startManagedAudioConversation: no active session")
            return
        }
        audioConversationJob = clientScope.launch {
            runCatching {
                session.startAudioConversation(
                    functionCallHandler = functionCallHandler,
                    transcriptHandler   = transcriptHandler,
                )
            }.onFailure { e ->
                Log.e(TAG, "startAudioConversation error: ${e.message}", e)
            }
        }
    }

    fun stopManagedAudioConversation() {
        runCatching { liveSession?.stopAudioConversation() }
            .onFailure { Log.w(TAG, "stopAudioConversation warning: ${it.message}") }
        audioConversationJob?.cancel()
        audioConversationJob = null
    }

    fun release() {
        clientScope.cancel()
        responseChannel.close()
    }

    // â”€â”€ ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /**
     * ĞœĞ°Ğ¿Ğ¿Ğ¸Ñ‚ LiveServerMessage â†’ GeminiResponse.
     *
     * LiveServerMessage â€” sealed class. LiveServerContent â€” Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ¿Ğ¾Ğ´Ñ‚Ğ¸Ğ¿.
     */
    private fun mapServerMessage(message: LiveServerMessage): GeminiResponse? {
        if (message is LiveServerContent) {
            return mapServerContent(message)
        }

        // Ğ”Ñ€ÑƒĞ³Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ‚Ğ¸Ğ¿Ñ‹ (LiveServerToolCall Ğ¸ Ñ‚.Ğ´.) â€” Ğ¿Ñ€Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸
        // startAudioConversation function calls Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ÑÑ‚ÑÑ Ñ‡ĞµÑ€ĞµĞ· callback.
        Log.d(TAG, "Received non-content message: ${message::class.simpleName}")
        return null
    }

    /**
     * ĞœĞ°Ğ¿Ğ¿Ğ¸Ñ‚ LiveServerContent â†’ GeminiResponse.
     *
     * LiveServerContent ÑĞ²Ğ¾Ğ¹ÑÑ‚Ğ²Ğ° (Ğ¸Ğ· PR firebase-android-sdk #7482):
     *   - content: Content?         â†’ parts: List<Part>
     *   - turnComplete: Boolean
     *   - interrupted: Boolean
     *   - generationComplete: Boolean
     *   - inputTranscription: Transcription
     *   - outputTranscription: Transcription
     *
     * âš ï¸ Ğ•ÑĞ»Ğ¸ InlineDataPart.inlineData Ğ½Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ â€” Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ .data
     * âš ï¸ Ğ•ÑĞ»Ğ¸ Transcription.text Ğ½Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ â€” Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ .content
     */
    private fun mapServerContent(sc: LiveServerContent): GeminiResponse? {
        val parts = sc.content?.parts.orEmpty()

        // Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾ (InlineDataPart â†’ PCM 24kHz)
        val audioData = parts
            .filterIsInstance<InlineDataPart>()
            .firstOrNull()
            ?.inlineData  // ByteArray â€” âš ï¸ ĞµÑĞ»Ğ¸ Ğ½Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ, Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ .data
            ?.takeIf { it.isNotEmpty() }

        // Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ñ‚ĞµĞºÑÑ‚
        val textContent = parts
            .filterIsInstance<TextPart>()
            .joinToString("") { it.text }
            .takeIf { it.isNotEmpty() }

        // Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ function calls (Ğ´Ğ»Ñ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ³Ğ¾ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ° Ğ±ĞµĞ· startAudioConversation)
        val functionCall = parts
            .filterIsInstance<FunctionCallPart>()
            .firstOrNull()
            ?.let { fc ->
                GeminiFunctionCall(
                    id       = fc.name,  // Ğ½ĞµÑ‚ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ id, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ name
                    name     = fc.name,
                    argsJson = fc.args.toString(),
                )
            }

        val isTurnComplete = sc.turnComplete
        val isInterrupted  = sc.interrupted

        // Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸ â€” âš ï¸ ĞµÑĞ»Ğ¸ .text Ğ½Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ, Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ .content
        val inputTranscript  = sc.inputTranscription?.text?.takeIf { it.isNotEmpty() }
        val outputTranscript = sc.outputTranscription?.text?.takeIf { it.isNotEmpty() }

        // Ğ•ÑĞ»Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ â€” Ğ½Ğµ ÑĞ¼Ğ¸Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼
        if (audioData == null && textContent == null && functionCall == null &&
            !isTurnComplete && !isInterrupted &&
            inputTranscript == null && outputTranscript == null) {
            return null
        }

        return GeminiResponse(
            audioData        = audioData,
            transcript       = textContent,
            functionCall     = functionCall,
            isTurnComplete   = isTurnComplete,
            isInterrupted    = isInterrupted,
            inputTranscript  = inputTranscript,
            outputTranscript = outputTranscript,
        )
    }

    // â”€â”€ ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ FunctionDeclaration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /**
     * ĞŸĞ°Ñ€ÑĞ¸Ñ‚ JSON-ÑÑ‚Ñ€Ğ¾ĞºÑƒ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ² FunctionDeclaration SDK.
     *
     * âœ… FunctionDeclaration Ğ²ÑĞµĞ³Ğ´Ğ° Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ parameters (Map<String, Schema>).
     *    Ğ”Ğ»Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¹ Ğ±ĞµĞ· Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² â†’ parameters = emptyMap().
     */
    private fun parseFunctionDeclaration(declarationJson: String): FunctionDeclaration {
        val obj = json.parseToJsonElement(declarationJson) as JsonObject

        val name        = (obj["name"]        as? JsonPrimitive)?.content ?: error("Missing 'name'")
        val description = (obj["description"] as? JsonPrimitive)?.content ?: ""
        val parametersObj = obj["parameters"] as? JsonObject

        val propertiesJson = parametersObj
            ?.let { it["properties"] as? JsonObject }
            ?: JsonObject(emptyMap())

        val required = parametersObj
            ?.let { it["required"] as? kotlinx.serialization.json.JsonArray }
            ?.mapNotNull { (it as? JsonPrimitive)?.content }
            ?: emptyList()

        val properties: Map<String, Schema> = propertiesJson.mapValues { (_, v) ->
            parseSchema(v as JsonObject)
        }

        return FunctionDeclaration(
            name               = name,
            description        = description,
            parameters         = properties,
            optionalParameters = properties.keys.filter { it !in required }.toList(),
        )
    }

    /**
     * ĞŸĞ°Ñ€ÑĞ¸Ñ‚ JSON Schema Ğ¾Ğ±ÑŠĞµĞºÑ‚ Ğ² Schema SDK.
     */
    private fun parseSchema(schemaJson: JsonObject): Schema {
        val type = (schemaJson["type"] as? JsonPrimitive)?.content?.uppercase() ?: "STRING"
        val description = (schemaJson["description"] as? JsonPrimitive)?.content

        return when (type) {
            "OBJECT" -> {
                val propertiesJson = schemaJson["properties"] as? JsonObject ?: JsonObject(emptyMap())
                val required = (schemaJson["required"] as? kotlinx.serialization.json.JsonArray)
                    ?.mapNotNull { (it as? JsonPrimitive)?.content }
                    ?: emptyList()

                val properties = propertiesJson.mapValues { (_, v) ->
                    parseSchema(v as JsonObject)
                }

                Schema.obj(
                    properties         = properties,
                    optionalProperties = properties.keys.filter { it !in required }.toList(),
                    description        = description,
                )
            }
            "STRING"  -> Schema.string(description = description)
            "NUMBER"  -> Schema.double(description = description)
            "INTEGER" -> Schema.integer(description = description)
            "BOOLEAN" -> Schema.boolean(description = description)
            "ARRAY"   -> {
                val itemsJson = schemaJson["items"] as? JsonObject
                val items = itemsJson?.let { parseSchema(it) } ?: Schema.string()
                Schema.array(items = items, description = description)
            }
            else -> Schema.string(description = description)
        }
    }
}

// â”€â”€ Response models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

data class GeminiResponse(
    val audioData: ByteArray?,
    val transcript: String?,
    val functionCall: GeminiFunctionCall?,
    val isTurnComplete: Boolean = false,
    val isInterrupted: Boolean = false,
    val inputTranscript: String? = null,
    val outputTranscript: String? = null,
) {
    fun hasAudio(): Boolean = audioData != null && audioData.isNotEmpty()
    fun hasFunctionCall(): Boolean = functionCall != null
    fun hasTranscript(): Boolean = !transcript.isNullOrEmpty()

    override fun equals(other: Any?): Boolean {
        if (this === other) return true
        if (other !is GeminiResponse) return false
        return transcript       == other.transcript &&
               functionCall     == other.functionCall &&
               isTurnComplete   == other.isTurnComplete &&
               isInterrupted    == other.isInterrupted &&
               inputTranscript  == other.inputTranscript &&
               outputTranscript == other.outputTranscript &&
               (audioData?.contentEquals(other.audioData) == true ||
                (audioData == null && other.audioData == null))
    }

    override fun hashCode(): Int {
        var result = transcript.hashCode()
        result = 31 * result + isTurnComplete.hashCode()
        result = 31 * result + isInterrupted.hashCode()
        result = 31 * result + (functionCall?.hashCode() ?: 0)
        return result
    }
}

data class GeminiFunctionCall(
    val id: String,
    val name: String,
    val argsJson: String,
)

class GeminiConnectionException(
    message: String,
    cause: Throwable? = null,
) : Exception(message, cause)
